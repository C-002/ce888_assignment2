{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_helper import NNWeightHelper\n",
    "from snes import SNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from dataSet import dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 1024\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 93\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    #clf = ExtraTreesClassifier(n_estimators=100, n_jobs=4)\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'back_pack': 0, 'bike': 1, 'bike_helmet': 2, 'bookcase': 3, 'bottle': 4, 'calculator': 5, 'desktop_computer': 6, 'desk_chair': 7, 'desk_lamp': 8, 'file_cabinet': 9, 'headphones': 10, 'keyboard': 11, 'laptop_computer': 12, 'letter_tray': 13, 'mobile_phone': 14, 'monitor': 15, 'mouse': 16, 'mug': 17, 'paper_notebook': 18, 'pen': 19, 'phone': 20, 'printer': 21, 'projector': 22, 'punchers': 23, 'ring_binder': 24, 'ruler': 25, 'scissors': 26, 'speaker': 27, 'stapler': 28, 'tape_dispenser': 29, 'trash_can': 30}\n"
     ]
    }
   ],
   "source": [
    "Amazon_path = './Original_images/amazon/images'\n",
    "dslr_path   = './Original_images/dslr/images'\n",
    "webcam_path = './Original_images/webcam/images'\n",
    "paths = [Amazon_path, dslr_path, webcam_path]\n",
    "files = os.listdir(Amazon_path)\n",
    "labels = {}\n",
    "count  = 0\n",
    "for key in files:\n",
    "    a = {key : count}\n",
    "    labels.update(a)\n",
    "    count += 1\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = []\n",
    "Amazon = dataSet()\n",
    "dslr   = dataSet()\n",
    "webcam = dataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Amazon dataSet...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Loading Amazon dataSet...')\n",
    "for dirname in files:\n",
    "    images_name = os.listdir(Amazon_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = Amazon_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        Amazon.upData(image_data, labels[dirname], labels)        \n",
    "Amazon.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading webcam dataSet...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Loading webcam dataSet...')\n",
    "for dirname in files:\n",
    "    images_name = os.listdir(webcam_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = webcam_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        webcam.upData(image_data, labels[dirname], labels)\n",
    "webcam.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Amazon.data\n",
    "y_train = Amazon.label\n",
    "x_test  = webcam.data\n",
    "y_test  = webcam.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2817, 28, 28, 3)\n",
      "y_train shape: (2817,)\n",
      "2817 train samples\n",
      "795 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation is over\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(31, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(\"compilation is over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31)                167679    \n",
      "=================================================================\n",
      "Total params: 168,575\n",
      "Trainable params: 168,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (168575,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "\n",
    "all_examples_indices = list(range(x_train.shape[0]))\n",
    "\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "print(y_test.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "# print('Test MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "\n",
    "    # to be provided back to snes\n",
    "    told = []\n",
    "    # use a small number of training samples for speed purposes\n",
    "    subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "    # evaluate on another subset\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "    # iterate over the population\n",
    "    for asked_j in asked:\n",
    "        # set nn weights\n",
    "        nnw.set_weights(asked_j)\n",
    "        # train the classifer and get back the predictions on the training data\n",
    "        clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "\n",
    "        # calculate the predictions on a different set\n",
    "        y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "        score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # clf, _ = train_classifier(model, x_train, y_train)\n",
    "        # y_pred = predict_classifier(model, clf, x_test)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        # append to array of values that are to be returned\n",
    "        told.append(score)\n",
    "\n",
    "    snes.tell(asked, told)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnw.set_weights(snes.center)\n",
    "\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "print(y_test.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
